# üç∑Marche al√©atoire


<img src="../_static/_medias/physic/thermo/brown/Cover_Brownien.png" alt="R√©mi MEVAERE">


# Introduction
Le mouvement brownien, aussi appel√© marche al√©atoire, rev√™t une importance particuli√®re dans l‚Äô√©tude de la nature. Il a permis √† l‚Äô√©poque de confirmer l‚Äôexistence des atomes, ainsi que d'√©valuer le nombre d‚ÄôAvogadro. Les recherches associ√©es √† ce mouvement sont encore utilis√©es aujourd'hui dans de nombreux domaines des sciences physiques, mais aussi en finance (notamment pour l'analyse des cours boursiers). On parle alors de processus stochastique. Ces travaux sont associ√©s √† des scientifiques prestigieux tels qu‚ÄôAlbert Einstein et Jean Perrin. On se propose dans ce petit papier de mod√©liser le mouvement brownien suivant une approche √©l√©mentaire. On se servira du mod√®le de l‚Äôivrogne (repr√©sentant une particule).[^3]

<iframe
  src="https://player.vimeo.com/video/1021995358?title=0&amp;byline=0&amp;portrait=0&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
  frameborder="0"
  allow="autoplay; fullscreen; picture-in-picture; clipboard-write"
  style="width:100%; height:500px;"
  title="Mouvement_Brownien">
</iframe>

## Robert Brown


```{image} ../_static/_medias/physic/thermo/brown/Robert_brown_botaniker.jpg
:width: 300px
:align: center
:class: vspace
```

Robert Brown (1773-1858) √©tait un botaniste √©cossais c√©l√®bre pour sa d√©couverte du mouvement Brownien en 1827. Ce ph√©nom√®ne se r√©f√®re √† l'agitation al√©atoire des particules microscopiques en suspension dans un fluide, qu'il observa en examinant des grains de pollen dans l'eau. Brown croyait initialement que ce mouvement √©tait une caract√©ristique des particules vivantes, mais il s'est vite rendu compte qu'il se produisait m√™me avec des particules inanim√©es. Le mouvement Brownien a √©t√© fondamental dans le d√©veloppement de la physique statistique, particuli√®rement dans les travaux d'Albert Einstein au d√©but du 20e si√®cle, qui a expliqu√© ce mouvement par les collisions entre les particules et les mol√©cules de fluide.[^1]
## Jean Perrin
(Physics/brownien/jeanperrin)=
```{image} ../_static/_medias/physic/thermo/brown/JeanPerrin.png
:width: 300px
:align: center
:class: vspace
```

Jean Perrin (1870-1942) √©tait un physicien fran√ßais Lillois qui a jou√© un r√¥le crucial dans la validation exp√©rimentale du mouvement brownien. En 1908, il a confirm√© les travaux th√©oriques d'Albert Einstein sur ce ph√©nom√®ne en √©tudiant la r√©partition des particules en suspension dans un liquide. Perrin a d√©montr√© que ce mouvement al√©atoire des particules √©tait caus√© par les collisions avec les mol√©cules du liquide, fournissant ainsi une preuve directe de l'existence des atomes et des mol√©cules. Ses travaux ont √©t√© essentiels pour √©tablir la th√©orie atomique, et en 1926, il a re√ßu le prix Nobel de physique pour ses contributions √† la physique mol√©culaire et atomique.[^2]
# Pr√©sentation du probl√®me

```{image} ../_static/_medias/physic/thermo/brown/drunk-1-630x1024.png
:width: 150px
:align: center
:class: vspace
```

```{caution}
L'objectif est de pr√©senter un code simple et compr√©hensible. Il ne s'agit pas d'optimiser excessivement le code Python üêç, ni de tirer parti des multiples c≈ìurs des processeurs modernes, et encore moins d'utiliser des biblioth√®ques comme CUDA, qui permettent le calcul massivement parall√®le sur un GPU. Une optimisation sommaire est propos√©e en annexe.
```

Dans l‚Äô√©tude du transport de grandeurs physiques par des mol√©cules, le physicien peut, en premi√®re approximation, adopter un mod√®le stochastique appel√© **marche al√©atoire**. C‚Äôest le cas, par exemple, pour l'interpr√©tation de la viscosit√©, qui peut √™tre consid√©r√©e comme le transport d'une quantit√© de mouvement. Comme mentionn√© plus haut, le mod√®le utilis√© est celui de l'ivrogne, o√π celui-ci effectue al√©atoirement un pas d'une longueur fixe, not√©e $l$, dans un sens ou dans l'autre.

## `Code 1` - repr√©sentation simple du mouvement de l‚Äôivrogne
```python
# Importation des biblioth√®ques n√©cessaires  
import random  # Pour g√©n√©rer des valeurs al√©atoires  
import matplotlib  # Pour configurer les param√®tres globaux de matplotlib  
import matplotlib.pyplot as plt  # Pour cr√©er des graphiques  
  
# Configuration globale de la r√©solution des graphiques  
matplotlib.rcParams['figure.dpi'] = 150  # D√©finit la r√©solution des images/vid√©os pour une meilleure qualit√© visuelle  
  
# Param√®tres  
NBR_PAS = 100  # Nombre de pas que fera l'ivrogne dans sa marche al√©atoire  
trajectoire = []  # Liste pour stocker les positions √† chaque pas  
  
# G√©n√©ration de la trajectoire avec marche al√©atoire (mod√®le de l'ivrogne)  
position = 0  # Initialisation de la position √† 0  
for i in range(NBR_PAS):  
    pas = random.choice([-1, 1])  # L'ivrogne fait un pas de +1m ou -1m (choix al√©atoire)  
    trajectoire.append(pas)  # Ajoute le pas √† la liste  
  
# Affichage du graphique  
plt.plot(trajectoire, ".:", linewidth=0.7, markersize=5, color="black", markeredgecolor="red")  # Trac√© de la courbe  
plt.title("Repr√©sentation du mouvement de l'ivrogne",fontsize=15)  # Titre du graphique  
plt.xlabel('Num√©ro du pas', fontsize=14)  # √âtiquette pour l'axe des x (le num√©ro du pas)  
plt.ylabel('Position (m)', fontsize=14)  # √âtiquette pour l'axe des y (la position en m√®tres)  
plt.yticks(range(min(trajectoire), max(trajectoire) + 1))  # Ajuste les graduations sur l'axe y pour montrer toutes les positions possibles  
plt.figtext(0.70, 0.015, 'R√©mi MEVAERE - sciences-physiques.net', fontsize=6, color='black', alpha=0.9, fontweight='normal')  # Ajout d'une mention en bas √† droite  
  
# Afficher ou sauvegarder l'image  
plt.show()  # Affiche le graphique √† l'√©cran
```

```{image} ../_static/_medias/physic/thermo/brown/RepresentationMvtIvrogne.png
:align: center
:class: vspace
```


## `Code 2` : Simulation de la trajectoire de 20 ivrognes parcourant 1000 pas 
```python
# Math√©matiques et calculs  
import random  
  
# Graphiques  
import matplotlib  
import matplotlib.pyplot as plt  
from matplotlib import animation  
  
# Configuration des param√®tres de Matplotlib pour les graphiques  
matplotlib.rcParams['animation.html'] = 'html5'  # Configuration pour affichage des animations  
matplotlib.rcParams['figure.dpi'] = 150  # D√©finition de la r√©solution des images  
  
# Constantes  
NBR_PAS = 1000  # Nombre de pas par ivrogne  
NBR_IVROGNE = 20  # Nombre d'ivrognes simul√©s  
trajectoires_ivrognes = []  # Liste pour stocker les trajectoires de chaque ivrogne  
X_MAX = 0  # Variable pour suivre la position maximale  
X_MIN = 0  # Variable pour suivre la position minimale  
  
# Simulation des trajectoires des ivrognes  
for b in range(NBR_IVROGNE):  
    pas = []  # Liste pour stocker les pas individuels  
    trajectoire = []  # Liste pour stocker la trajectoire cumul√©e  
    # Simulation des pas pour un ivrogne    for i in range(NBR_PAS):  
        pas.append(random.choice([-1, 1]))  # Choix al√©atoire d'un pas (-1 ou 1)  
        trajectoire.append(sum(pas))  # Mise √† jour de la trajectoire  
    # Enregistrer la trajectoire de cet ivrogne    trajectoires_ivrognes.append(trajectoire)  
    # Mettre √† jour les bornes pour l'axe des ordonn√©es  
    MAX_TRAJ = max(trajectoire)  
    MIN_TRAJ = min(trajectoire)  
    if MAX_TRAJ > X_MAX:  
        X_MAX = MAX_TRAJ  
    if MIN_TRAJ < X_MIN:  
        X_MIN = MIN_TRAJ  
  
# Cr√©ation d'une liste des num√©ros de pas pour l'axe des abscisses  
num_pas = [i for i in range(NBR_PAS)]  
  
# Cr√©ation de la figure et de l'axe pour le graphique  
fig, ax = plt.subplots()  
ax = plt.axis([0, NBR_PAS, X_MIN-2, X_MAX+2])  # D√©finition des limites de l'axe  
  
# Cr√©ation des objets "courbe" pour chaque ivrogne  
courbe = []  
for c in range(NBR_IVROGNE):  
    courbe.append(plt.plot([0], [0], '-', linewidth=1, solid_joinstyle='round', label="Ivrogne n¬∞" + str(c)))  # Initialiser les courbes  
  
# Embellissement du graphique  
plt.title("Trajectoire des ivrognes", fontsize=15)  
plt.xlabel('Num√©ro du pas', fontsize=14)  
plt.ylabel("Position (m)", fontsize=14)  
plt.figtext(0.70, 0.015, 'R√©mi MEVAERE - sciences-physiques.net', fontsize=6, color='black', alpha=0.9, fontweight='normal')  # Ajout d'une mention en bas √† droite  
  
# Fonction d'animation appel√©e pour chaque frame  
def animate(i):  
    # Mettre √† jour les donn√©es pour chaque ivrogne  
    for b in range(NBR_IVROGNE):  
        courbe[b][0].set_data(num_pas[0:i], trajectoires_ivrognes[b][0:i])  # Mettre √† jour les points trac√©s  
  
# Cr√©ation d'une animation, en cr√©ant un graphique image par image  
myAnimation = animation.FuncAnimation(fig, animate, frames=NBR_PAS, interval=20, repeat=False)  
  
# Sauvegarde de l'animation dans un fichier .mp4 (optionnel)  
myAnimation.save("trajectoire_ivrognes.mp4", writer="ffmpeg")  
  
# Affichage du graphique anim√©  
plt.show()
```



<iframe
  src="https://player.vimeo.com/video/1022228940?title=0&amp;byline=0&amp;portrait=0&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
  frameborder="0"
  allow="autoplay; fullscreen; picture-in-picture; clipboard-write"
  style="width:100%; height:500px;"
  title="Trajectoire des ivrognes">
</iframe>




# Probl√©matique
Quelle est la probabilit√© que l'ivrogne effectue, au total, un d√©placement de $\mathbf{x}$ m√®tres dans la direction des $\mathbf{x > 0}$ ?


# R√©solution
## √âpreuve de Bernoulli
Nous nous pla√ßons, comme il est fr√©quent en physique, dans un cas simplifi√©. Nous consid√©rons une **marche al√©atoire unidimensionnelle**, d√©crite le long d'un unique axe $\mathbf{x}$. Il sera, par la suite, plus ais√© de g√©n√©raliser ce r√©sultat √† un mouvement tridimensionnel, plus repr√©sentatif de la r√©alit√© physique. L‚Äôimage en en-t√™te d‚Äôailleurs repr√©sente un mod√®le plus complexe de mouvement stochastique √† deux dimensions.

Sur le plan math√©matique, nous nous appuierons sur des concepts de probabilit√©. Chaque d√©placement de l'ivrogne correspond √† une _√©preuve_, et l‚Äôexp√©rience consiste en une succession de $\mathbf{N}$ _√©preuves_. Chaque √©preuve peut conduire √† l'un des deux √©v√©nements √©quiprobables suivants :

- `√âv√©nement +` : la particule se d√©place dans la direction des $\mathbf{x}$ positifs ;
- `√âv√©nement -` : la particule se d√©place dans la direction des $\mathbf{x}$ n√©gatifs.

Relions $\mathbf{n}$, le nombre de pas vers la droite (positifs), avec $\mathbf{N}$ (le nombre total de d√©placements) et $\mathbf{m}$ la position finale sur l'axe des $x$. La position finale $m$ est donn√©e par la diff√©rence entre le nombre de pas vers la droite $n$ et le nombre de pas vers la gauche $(N - n)$ : 

$$ m = n - (N - n) = 2n - N \quad \implies \quad n = \frac{m + N}{2}$$

> [!info]  Remarque üß†
> Nous pourrions suivre le m√™me raisonnement en param√©trant les d√©placements vers la gauche plut√¥t que ceux vers la droite ; les r√©sultats finaux seraient identiques. En effet, dans notre mod√®le, l'ivrogne n'a pas de raison particuli√®re de privil√©gier un d√©placement vers la gauche par rapport √† un pas vers la droite (les directions sont √©quiprobables, $p_{\pm} = 0{,}5$). 

On peut ensuite se demander quelle est la probabilit√© d'obtenir $\mathbf{n}$ d√©placements vers la droite parmi $\mathbf{N}$ √©preuves. C'est-√†-dire, quelle est la probabilit√© que l'ivrogne aille $\mathbf{n}$ fois vers la droite lorsqu'il effectue $\mathbf{N}$ d√©placements au total. La **loi binomiale** vue en math√©matiques au lyc√©e r√©pond √† cette question : 

$$ \large{p(n, N) =C^{n}_{N}.p^{n}_{+}.p^{N-n}_{-}= \binom{N}{n} \, p_{+}^{\, n} \, p_{-}^{\, N - n}} $$

> [!warning]  Notation üñçÔ∏è  
>  $p_{+}^{\, n}$ repr√©sente la probabilit√© d'effectuer un d√©placement vers la droite, √©lev√©e √† la puissance $n$.
> 
## Avec le th√©or√®me central limite

Pour calculer la probabilit√© que l'ivrogne se retrouve en position $m$ apr√®s $N$ pas, on utilisera le **th√©or√®me central limite** (tr√®s utile lorsque $N$ est grand). 

> [!TIP] Pourquoi utiliser le th√©or√®me central limite ?
> Le th√©or√®me central limite est fondamental en probabilit√© et en statistique, il nous permet d'approcher la distribution binomiale par une loi normale (gaussienne), ce qui simplifie les calculs. Il affirme que la somme de variables al√©atoires ind√©pendantes et identiquement distribu√©es tend vers une distribution normale lorsque le nombre de variables augmente. 
> 
> ** Pertinence :**
> - Chaque d√©placement √©l√©mentaire de l'ivrogne est une variable al√©atoire ind√©pendante ;
> - Les d√©placements sont identiquement distribu√©s (chaque pas a la m√™me probabilit√© d'√™tre √† gauche ou √† droite) ;
> 
>** Int√©r√™t : **
>  - **Simplicit√© de calcul** : Au lieu de manipuler des distributions binomiales complexes pour de grandes valeurs de $N$, on utilise une gaussienne, beaucoup plus facile √† g√©rer analytiquement ; 
>  - **Pr√©vision des comportements** : Il permet de pr√©dire la probabilit√© de trouver l'ivrogne √† une certaine distance de son point de d√©part apr√®s un grand nombre de pas. 
>  - **Universalit√©** : Ce th√©or√®me est applicable √† de nombreux syst√®mes physiques o√π des variables al√©atoires ind√©pendantes s'additionnent, comme en physique statistique, en thermodynamique ou en finance.

### Variable al√©atoire : d√©placement √©l√©mentaire
D√©finissons une variable al√©atoire nomm√©e **d√©placement √©l√©mentaire** not√©e $\delta X_i$, ayant deux valeurs possibles $\delta X_i = \pm 1$ : 
- $\delta X_i = +l$ si l'ivrogne se d√©place vers la droite. 
- $\delta X_i = -l$ si l'ivrogne se d√©place vers la gauche. 


La variable al√©atoire $X_N$, somme des petits d√©placements √©l√©mentaires repr√©sente la position finale $m$ de l'ivrogne apr√®s $N$ pas : 

$$ \large{X_N = \sum_{i=1}^{N} \delta X_i} = m $$
### Esp√©rance

$$ \begin{align*} \langle \delta X_i \rangle  &= p_{+} \times (+1) + p_{-} \times (-1) = p_{+}\times 1 - (1-p_{+})\times 1=2  p_{+} - 1 \\ &= 2 \left( \dfrac{1}{2}  \right) - 1  =0 \end{align*} $$

Le r√©sultat √©tant trivial vu que les deux √©v√®nements sont √©quiprobables.

### Variance
$$ \langle (\delta X_i)^2 \rangle = p_{+} \times (+1)^2 + p_{-} \times (-1)^2   =p_{+}+(1-p_{+})= 1$$
### Ecart-type
$$\sigma_{\delta X}^2= \langle (\delta X_i)^2 \rangle - \langle \delta X_i \rangle^2 = 1$$
### Application du Th√©or√®me
Le **th√©or√®me central limite** stipule que pour $N \gg 1$, la variable al√©atoire $X_N$ suit approximativement une loi normale centr√©e sur $N \cdot \langle \delta X_i \rangle$ (ici 0) et de variance $N \cdot \sigma_{\delta X}^2$ (ici $N$) : 

$$ P(X_N) = \frac{1}{\sqrt{2\pi \cdot N \sigma_{\delta X}^2}} \exp \left[ - \frac{(X_N - N \cdot \langle \delta X_i \rangle )^2}{2 \cdot N \sigma_{\delta X}^2} \right] $$

En rempla√ßant $\langle \delta X_i \rangle = 0$ et $\sigma_{\delta X}^2 = 1$, on obtient : 

$$ P(X_N) = \frac{1}{\sqrt{2\pi N}} \exp \left[ - \frac{X_N^2}{2 N} \right] $$

√âtant donn√© que le d√©placement net $m$ est √©gal √† $X_N$, la probabilit√© de trouver l'ivrogne en position $x$ apr√®s $N$ pas est donn√©e par : 

$$ \LARGE\boxed{P(n) = \frac{1}{\sqrt{2\pi N }} \exp \left[ - \dfrac{m^2}{2 N } \right]} $$
### `Code 3` - V√©rification de la distribution normale

> [!NOTE] D√©placement
> Pour la simulation on se facilite la t√¢che en utilisant un d√©placement $l=\pm 1$

```python
import numpy as np  
import matplotlib  
import matplotlib.pyplot as plt  
from matplotlib import animation  
  
# Constantes  
NBR_PAS = 100  # Nombre de pas pour chaque ivrogne  
NBR_IVROGNES = 900000  # Nombre total d'ivrognes simul√©s  
  
# Configuration des param√®tres de Matplotlib pour les graphiques  
matplotlib.rcParams['animation.html'] = 'html5'  # Configuration pour affichage des animations  
matplotlib.rcParams['figure.dpi'] = 150  # D√©finition de la r√©solution des images  
  
# Simulation des positions finales des ivrognes  
deplacements = np.random.choice([-1, 1], size=(NBR_IVROGNES, NBR_PAS))  
positions_finales = np.sum(deplacements, axis=1)  
  
# D√©termination des positions minimale et maximale pour ajuster les limites du graphique  
MIN, MAX = positions_finales.min(), positions_finales.max()  
  
# Pr√©paration de la figure pour l'animation  
fig, ax = plt.subplots()  
ax.set_xlim(MIN - 5, MAX + 5)  
plt.xlabel('Position finale', fontsize=12)  
plt.ylabel("Probabilit√©", fontsize=12)  
plt.title('Distribution des positions finales des ivrognes')  
  
plt.figtext(0.70, 0.015, 'sciences-physiques.net', fontsize=6, color='black', alpha=0.9,  
            fontweight='normal')  
  
# Initialisation de l'histogramme  
nombre_bandes = MAX - MIN + 1  
  
# Calcul de la courbe gaussienne th√©orique  
x_gauss = np.linspace(MIN, MAX, 1000)  
P_gauss = (1 / np.sqrt(2 * np.pi * NBR_PAS)) * np.exp(-x_gauss ** 2 / (2 * NBR_PAS))  
  
  
# Fonction d'animation pour mettre √† jour l'histogramme  
def animer_histogramme(i):  
    plt.cla()  # Efface le contenu pr√©c√©dent de la figure  
    donnees_histogramme = positions_finales[0:i]  # S√©lectionne les positions jusqu'√† l'ivrogne i  
  
    # Tracer l'histogramme normalis√© (probabilit√©s)    comptes, bandes, patches = plt.hist(donnees_histogramme, bins=nombre_bandes, range=(MIN - 0.5, MAX + 0.5),  
                                        density=True, facecolor='blue', alpha=0.5, edgecolor='black')  
  
    # Calcul de la largeur des bandes  
    largeur_bande = bandes[1] - bandes[0]  
  
    # Tracer la courbe th√©orique gaussienne ajust√©e √† la largeur des bandes  
    plt.plot(x_gauss, P_gauss * largeur_bande * 2, color='red', lw=2, label='Gaussienne th√©orique')  
  
    # Mise √† jour des param√®tres de la figure  
    plt.title(f"Distribution des positions finales : {i} ivrogne(s)", fontsize=15)  
    plt.xlabel('Position finale', fontsize=14)  
    plt.ylabel("Probabilit√©", fontsize=14)  
    plt.xlim(MIN - 5, MAX + 5)  
    plt.ylim(0, max(comptes.max(), (P_gauss * largeur_bande).max()) * 1.1)  # Ajustement dynamique des ordonn√©es  
  
  
# Cr√©ation de la liste des frames pour l'animation  
liste_frames = (  
        list(range(1, 11)) +  
        [i * 10 for i in range(2, 11)] +  
        [i * 100 for i in range(2, 11)] +  
        [i * 1000 for i in range(2, 11)] +  
        [i * 10000 for i in range(2, NBR_IVROGNES // 10000 + 1)]  
)  
  
# Ajustement des marges pour laisser de l'espace autour des axes  
plt.subplots_adjust(left=0.15, right=0.95, top=0.9, bottom=0.1)  
  
# Cr√©ation de l'animation en utilisant la fonction animer_histogramme  
mon_animation = animation.FuncAnimation(fig, animer_histogramme, frames=liste_frames, interval=200, repeat=False)  
  
# Optionnel : sauvegarde de l'animation dans un fichier vid√©o  
mon_animation.save("distribution_ivrognes.mp4", writer="ffmpeg")  
  
# Affichage de l'animation  
plt.show()
```
<iframe
  src="https://player.vimeo.com/video/1022228674?title=0&amp;byline=0&amp;portrait=0&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479"
  frameborder="0"
  allow="autoplay; fullscreen; picture-in-picture; clipboard-write"
  style="width:100%; height:500px;"
  title="Trajectoire des ivrognes">
</iframe>

## Probabilit√© de parcourir une distance $x$
Revenons √† l'ivrogne. Nous cherchons √† conna√Ætre la distance $\mathbf{x}$ parcourue apr√®s une dur√©e d√©termin√©e $\mathbf{\Delta t}$. On se rappelle que $\mathbf{m}$ est la position finale en nombre de pas (la diff√©rence entre le nombre de pas vers la droite et vers la gauche). Les relations entre ces grandeurs sont ($l$ est la longueur d'un pas) :

$$\mathbf{x} = m \times l$$

De plus, la dur√©e totale est donn√©e par ($N$ est le nombre total de pas, $\tau$ est la dur√©e d'un pas) :

$$
\Delta t = N \times \tau
$$

En utilisant ces relations, on peut exprimer la probabilit√© de trouver l'ivrogne √† une distance $x$ apr√®s un temps $\Delta t$. √Ä partir de la distribution obtenue pr√©c√©demment pour $P(m)$, en rempla√ßant $m$ par $\dfrac{x}{l}$, on obtient :

$$P(m) = \frac{1}{\sqrt{2\pi N}} \exp\left( - \frac{m^2}{2N} \right) \quad \implies \quad \large\boxed{{P(x)  \frac{1}{\sqrt{2\pi N}} \exp\left( - \frac{x^2}{2 N l^2} \right)}}$$

Sachant que $N = \dfrac{\Delta t}{\tau}$, on peut aussi √©crire :

$$P(x) = \frac{1}{\sqrt{2\pi \dfrac{\Delta t}{\tau}}} \exp\left( - \frac{x^2}{2 \dfrac{\Delta t}{\tau} l^2} \right) = \frac{1}{\sqrt{2\pi \dfrac{\Delta t}{\tau}}} \exp\left( - \frac{\tau x^2}{2 \Delta t l^2} \right)  = \dfrac{1}{\sqrt{2\pi \dfrac{\Delta t}{\tau}}} \exp\left[ - \dfrac{\tau x^2}{2 \Delta t l^2} \right]$$

### Distance quadratique moyenne parcourue

Nous souhaitons calculer la valeur moyenne de $x^2$, not√©e $\langle x^2 \rangle$, qui est donn√©e par :

$$
\large\langle x^2 \rangle = \int_{-\infty}^{+\infty} x^2 P(x) \, dx
$$

Mais √©tant donn√© que $P(x)$ est une distribution gaussienne centr√©e en $0$, nous savons que ($\sigma^2$ est la variance de la distribution), l‚Äôidentification est ais√©e :

$$
\langle x^2 \rangle = \sigma^2 = N l^2 = \left( \dfrac{\Delta t}{\tau} \right) l^2
$$
Ainsi, la distance quadratique moyenne parcourue est ($l>0$, $\Delta t>0$, $\tau >0$) :

$$
\boxed{x_q = \sqrt{\langle x^2 \rangle} = l \sqrt{\dfrac{\Delta t}{\tau}}= l \cdot N}
$$

### Interpr√©tation physique

La distribution s'√©largit proportionnellement √† la racine carr√©e de la dur√©e $\Delta t$. Autrement dit, la r√©gion visit√©e par la particule (l'ivrogne) cro√Æt comme la racine carr√©e de la dur√©e de l'exp√©rience. Ce comportement est caract√©ristique d'un processus de diffusion, o√π la dispersion des particules augmente avec le temps de mani√®re proportionnelle √† $\sqrt{\Delta t}$.

### `Code 4` - Accord avec la th√©orie

> [!WARNING] Optimization üî©
> Sur mon ordinateur, ce code absolument pas optimis√© prend une dur√©e tr√®s longue (plus de 16 minutes). Les versions Vectoris√©e et CUDA disponibles en **Annexes** sont beaucoup plus rapides (40 secondes et 3 secondes).

```python
import random  
import numpy as np  
import matplotlib  
import matplotlib.pyplot as plt  
  
# Configuration des param√®tres de Matplotlib pour les graphiques  
matplotlib.rcParams['figure.dpi'] = 150  # R√©solution des images  
  
# Constantes  
NBR_IVROGNES = 2000  # Nombre d'ivrognes simul√©s  
liste_NBR_PAS = (  
    list(range(10, 110, 20)) +  
    list(range(200, 1100, 200)) +  
    list(range(2000, 11000, 2000)) +  
    list(range(20000, 110000, 20000)) +  
    list(range(200000, 1000000, 200000))  
)  
distances_quadratiques_moyennes = []  # Liste pour stocker les distances quadratiques moyennes  
distances_theoriques = []  # Liste pour stocker les distances th√©oriques  
  
# Simulation pour chaque nombre de pas  
for NBR_PAS in liste_NBR_PAS:  
    positions_finales = []  # Liste pour stocker les positions finales des ivrognes  
    # Simulation des ivrognes    for _ in range(NBR_IVROGNES):  
        position = 0  # Position initiale  
        # Simulation des pas pour un ivrogne        for _ in range(NBR_PAS):  
            pas = random.choice([-1, 1])  # Choix al√©atoire d'un pas (-1 ou 1)  
            position += pas  # Mise √† jour de la position  
        positions_finales.append(position)  
    # Calcul de la distance quadratique moyenne pour ce nombre de pas  
    distances_quadratiques = [pos**2 for pos in positions_finales]  
    distance_quadratique_moyenne = sum(distances_quadratiques) / NBR_IVROGNES  
    distances_quadratiques_moyennes.append(distance_quadratique_moyenne)  
    # Calcul de la distance th√©orique  
    distance_theorique = NBR_PAS  # Pour une marche al√©atoire simple en 1D  
    distances_theoriques.append(distance_theorique)  
  
# Conversion en tableaux numpy pour faciliter le trac√©  
liste_NBR_PAS_np = np.array(liste_NBR_PAS)  
distances_quadratiques_moyennes_np = np.array(distances_quadratiques_moyennes)  
distances_theoriques_np = np.array(distances_theoriques)  
  
# Cr√©ation du graphique  
plt.figure(figsize=(8, 5))  
plt.plot(liste_NBR_PAS_np, distances_theoriques_np, '--', label='Th√©orie')  
plt.plot(liste_NBR_PAS_np, distances_quadratiques_moyennes_np, 'o', label='Simulation', markeredgewidth=2, markersize=2)  
plt.xscale('log')  
plt.yscale('log')  
plt.xlabel('Nombre de pas (√©chelle logarithmique)', fontsize=14)  
plt.ylabel('Distance quadratique moyenne $\\langle x^2 \\rangle$', fontsize=14)  
plt.title('$\\langle x^2 \\rangle$ = f(nombre de pas)    (Python Simple)', fontsize=15)  
plt.legend()  
plt.grid(True, which="both", ls="--")  
plt.figtext(0.70, 0.015, 'www.sciences-physiques.net', fontsize=6, color='black', alpha=0.9, fontweight='normal')  
plt.show()
```

```{image} ../_static/_medias/physic/thermo/brown/TheorieSimulation.png
:align: center
:class: vspace
```

# Conclusion

La distance quadratique moyenne parcourue par l'ivrogne est proportionnelle √† $\sqrt{\Delta t}$, ce qui signifie que la zone explor√©e s'√©tend de plus en plus lentement avec le temps. Ce r√©sultat est fondamental pour comprendre les ph√©nom√®nes de diffusion et de transport dans divers domaines scientifiques. Il illustre comment une succession de d√©placements al√©atoires conduit √† une dispersion des positions qui suit une loi gaussienne. Le fait que la largeur de la distribution augmente comme $\sqrt{\Delta t}$ est une caract√©ristique cl√© des processus diffusifs, tels que la diffusion des particules en physique ou la propagation des erreurs en statistiques.
# Annexes
## Math√©matiques
### Int√©grale $I$
La premi√®re int√©grale √† calculer est :

$$
I = \int^{\infty}_{-\infty} exp(- \alpha x^2) dx
$$

En prenant au carr√© l'int√©grale

$$
I^2 = \int^{\infty}_{-\infty} exp(- \alpha x^2) dx  \times \int^{\infty}_{-\infty} exp(- \alpha y^2) dy = \int^{\infty}_{-\infty}  \int^{\infty}_{-\infty} exp[- \alpha (x^2 + y^2)] dx dy
$$

On s'empresse de passer en coordonn√©e polaire :

$$
I^2  = \int^{\infty}_0 \int^{2\pi}_0 exp(-\alpha r^2) \, r dr d \theta 
$$

$$
I^2  = \int^{\infty}_0  exp(-\alpha r^2) \, r dr \times \int^{2\pi}_0 d \theta 
$$

Que l'on sait calculer facilement apr√®s un changement de variable ($u=r^2$) :

$$
I^2  = \frac{1}{2} \int^{\infty}_0  exp(-\alpha u)  du \times \int^{2\pi}_0 d \theta  = \pi  \int^{\infty}_0  exp(-\alpha u)  du= - \frac{\pi}{\alpha} \left[exp(-\alpha u) \right]^\infty_0 
$$

La racine carr√©e donne le r√©sultat de l‚Äôint√©grale :

$$
\large\boxed{I = \int^{\infty}_{-\infty} exp(- \alpha x^2) dx = \sqrt{\frac{\pi}{\alpha}}}
$$
### Int√©grale $J$

$$
J = \int^{\infty}_{-\infty} x^2 exp(- \alpha x^2)\, dx
$$

Or l'int√©grale $J$ est l'oppos√©e de la d√©riv√©e de $I$ par rapport √† $\alpha$, c'est √† dire :

$$
J = - \frac{d I}{d \alpha} = \int^{\infty}_{-\infty} x^2 exp(- \alpha x^2)\,  dx
$$

$$
J = \int^{\infty}_{-\infty} x^2 exp(- \alpha x^2) dx= - \frac{d }{d \alpha} \left(\sqrt{\frac{\pi}{\alpha}} \right)
$$
$$
\large\boxed{J =\frac{1}{2} \sqrt{\frac{\pi}{\alpha^3}}}
$$
### Compl√©ments sur la Gaussienne

Une distribution gaussienne classique a la forme :

$$
\large P(x) = \dfrac{1}{\sqrt{2\pi \sigma^2}} \exp\left( - \dfrac{(x - \mu)^2}{2 \sigma^2} \right)
$$

l'esp√©rance $\langle x \rangle = \mu$ et la variance $\sigma^2$ sont donn√©es par :

  $$
  \large \langle x \rangle = \int_{-\infty}^{+\infty} x P(x) \, dx = \mu \quad \text{et} \quad   \large \langle x^2 \rangle - \langle x \rangle^2 = \sigma^2
  $$

Dans le cas de cet article, la gaussienne est centr√©e en 0 ($\mu = 0$), donc :

$$
\langle x^2 \rangle = \sigma^2
$$

### Formule de Stirling
L'**approximation de Stirling** est une formule qui donne une estimation de la factorielle d'un grand nombre $N$. Elle est extr√™mement utile en math√©matiques et en physique, notamment en probabilit√©s et en statistiques. L'approximation est donn√©e par : 

$$ N! \approx N^N e^{-N} \sqrt{2\pi N} $$

**La factorielle d'un entier naturel** $N$ est d√©fini comme le produit de tous les entiers de $1$ √† $N$ : 

$$ N! = 1 \times 2 \times 3 \times \dots \times N $$

Pour des valeurs de $N$ grandes, calculer $N!$ directement devient rapidement impraticable en raison de la taille √©norme des nombres impliqu√©s. 

**Logarithme du factorielle**
Pour faciliter les manipulations math√©matiques, il est souvent utile de travailler avec le **logarithme** de la factorielle plut√¥t que la factorielle elle-m√™me. En prenant le logarithme naturel de $N!$, nous obtenons : 

$$ \ln N! = \ln(1 \times 2 \times 3 \times \dots \times N) = \sum_{k=1}^N \ln k $$

Cette somme peut √™tre difficile √† calculer directement, mais pour de grandes valeurs de $N$, nous pouvons l'approcher en utilisant une **int√©grale**. L'id√©e est d'approximer la somme discr√®te par une int√©grale continue. En effet, pour une fonction suffisamment r√©guli√®re, la somme des valeurs de la fonction en des points discrets peut √™tre approch√©e par l'int√©grale de cette fonction. Ainsi, nous avons : 

$$ \sum_{k=1}^N \ln k \approx \int_{1}^{N} \ln x \, dx $$

$$ \int_{1}^{N} \ln x \, dx = [x \ln x - x]_1^{N} = (N \ln N - N) - (1 \ln 1 - 1) = N \ln N - N + 1 $$ 

Comme $\ln 1 = 0$, le terme $1 \ln 1$ dispara√Æt, et nous obtenons : 

$$ \ln N! \approx N \ln N - N + 1 $$ 

Pour de grandes valeurs de $N$, le terme constant $+1$ est n√©gligeable, donc : 

$$ \ln N! \approx N \ln N - N $$

**Ajout du terme de correction avec la formule d'Euler-Maclaurin**

La formule d'Euler-Maclaurin est donn√©e par : 

$$ \sum_{k=a}^{b} f(k) = \int_{a}^{b} f(x) \, dx + \frac{f(a) + f(b)}{2} + \sum_{n=1}^{m} \frac{B_{2n}}{(2n)!} \left( f^{(2n-1)}(b) - f^{(2n-1)}(a) \right) + R_m $$

- $B_{2n}$ sont les nombres de Bernoulli
- $R_m$  est le reste apr√®s $m$ termes. 

Pour notre approximation, nous n√©gligeons les termes d'ordre sup√©rieur (de plus les d√©riv√©es impaires de $\ln x$ diminuent rapidement et les nombres de Bernoulli alternent en signe et diminuent en magnitude, nous n√©gligeons donc ces termes pour $N$  grand) et le reste $R_m$ il ne reste que le terme moyen de correction √† ajouter :

$$ \frac{f(1) + f(N)}{2} = \frac{\ln 1 + \ln N}{2} = \frac{0 + \ln N}{2} = \frac{\ln N}{2} $$

$$ \ln N! \approx N \ln N - N + \frac{1}{2} \ln N $$

Revenons √† $N!$ en prenant l'exponentielle des deux c√¥t√©s : 

$$ N! \approx e^{N \ln N - N + \frac{1}{2} \ln N} = e^{N \ln N - N} \cdot e^{\frac{1}{2} \ln N} $$

$$ N! \approx e^{N \ln N - N} \cdot \sqrt{N} $$

$$ e^{N \ln N - N} = N^N e^{-N} \quad \implies \quad  N! \approx N^N e^{-N} \sqrt{N}$$

**M√©thode de Laplace pour approximation plus pr√©cise** 

L'approximation de Stirling compl√®te inclut un facteur $\sqrt{2\pi N}$ pour am√©liorer la pr√©cision, surtout pour des valeurs de $N$ moins grandes. Pour justifier l'apparition de ce facteur, nous pouvons utiliser la **m√©thode de Laplace**.

La factorielle est li√©e √† la **fonction Gamma** par :

$$N! = \Gamma(N+1) = \int_{0}^{\infty} x^N e^{-x} \, dx = \int_{0}^{\infty} e^{N \ln x - x} \, dx$$

Nous allons appliquer la m√©thode de Laplace √† cette int√©grale :

$$I = \int_{0}^{\infty} e^{N f(x)} \, dx \implies f(x) = \ln x - \frac{x}{N}$$

**Trouver le maximum de** $f(x)$

$$f'(x) = \frac{1}{x} - \frac{1}{N}$$
$$f'(x)=0 \implies \frac{1}{x} - \frac{1}{N} = 0 \implies x = N$$
$$f''(x) = -\frac{1}{x^2} \implies f''(N) = -\frac{1}{N^2}$$

Le d√©veloppement de Taylor de $f(x)$ autour de $x = N$ est :

$$f(x) \approx f(N) + \frac{f''(N)}{2} (x - N)^2 =  \ln N - 1 - \frac{1}{2N^2} (x - N)^2$$
$$N f(x) \approx N (\ln N - 1) - \frac{(x - N)^2}{2N}$$

L'int√©grale devient :

$$I \approx e^{N f(N)} \int_{-\infty}^{\infty} e^{-\frac{(x - N)^2}{2N}} \, dx$$

*Remarque :* Nous avons √©tendu les bornes d'int√©gration √† $(-\infty, \infty)$ car la contribution significative provient d'une r√©gion √©troite autour de $x = N$ pour $N$ grand.

L'int√©grale est une int√©grale gaussienne connue :

$$\int_{-\infty}^{\infty} e^{-\frac{(x - N)^2}{2N}} \, dx = \sqrt{2\pi N}$$

En combinant les r√©sultats, nous obtenons :

$$I \approx e^{N f(N)} \sqrt{2\pi N} = e^{N \ln N - N} \sqrt{2\pi N}$$


Comme $I = N!$, nous obtenons l'approximation de Stirling compl√®te :

$$N! \approx N^N e^{-N} \sqrt{2\pi N}$$
## Physique
### D√©monstration avec la formule de Stirling
$$ \large{p(n, N) =C^{n}_{N}.p^{n}_{+}.p^{N-n}_{-}= \binom{N}{n} \, p_{+}^{\, n} \, p_{-}^{\, N - n}} $$

Pour calculer la probabilit√© que l'ivrogne se retrouve en position $m$ apr√®s $N$ pas, nous allons utiliser l'**approximation de Stirling** pour simplifier le calcul du coefficient binomial lorsque $N$ est grand.

**Approximation de Stirling**

Pour des grands nombres $N$, l'approximation de Stirling pour la factorielle est donn√©e par :

$$
N! \approx N^N e^{-N} \sqrt{2\pi N} \quad \implies \quad \ln N! \approx N \ln N - N + \frac{1}{2} \ln(2\pi N)
$$

**Calcul du logarithme de la probabilit√©**


$$
p(n, N) = \frac{N!}{n! (N - n)!} \left( \frac{1}{2} \right)^N \quad \implies \quad \ln p(n, N) = \ln N! - \ln n! - \ln (N - n)! - N \ln 2
$$

$$
\begin{align*}
\ln N! &\approx N \ln N - N + \frac{1}{2} \ln(2\pi N) \\
\ln n! &\approx n \ln n - n + \frac{1}{2} \ln(2\pi n) \\
\ln (N - n)! &\approx (N - n) \ln (N - n) - (N - n) + \frac{1}{2} \ln [2\pi (N - n)]
\end{align*}
$$
Substituons ces expressions dans $\ln p(n, N)$ :

$$
\begin{align*}
\ln p(n, N) &\approx [N \ln N - N + \frac{1}{2} \ln(2\pi N)] \\
&\quad - [n \ln n - n + \frac{1}{2} \ln(2\pi n)] \\
&\quad - [(N - n) \ln (N - n) - (N - n) + \frac{1}{2} \ln(2\pi (N - n))] \\
&\quad - N \ln 2
\end{align*}
$$
$$
\begin{align*}
\ln p(n, N) &\approx N \ln N - N - n \ln n + n - (N - n) \ln (N - n) + (N - n) \\
&\quad + \frac{1}{2} \ln(2\pi N) - \frac{1}{2} \ln(2\pi n) - \frac{1}{2} \ln[2\pi (N - n)] - N \ln 2
\end{align*}
$$

$$
\large\boxed{\ln p(n, N) \approx N \ln N - n \ln n - (N - n) \ln (N - n) - N \ln 2}
$$
**Ecriture avec les grandeurs du probl√®me**

Nous pouvons √©crire $n$ et $N - n$ en fonction de $N$ et $m$ :

 $$ m = n - (N - n) = 2n - N \quad \implies \quad n = \frac{m + N}{2} \quad \text{et} \quad N - n = \frac{N - m}{2}$$

$$
\begin{align*}
\ln p(m, N) &\approx N \ln N - \left( \frac{N + m}{2} \right) \ln \left( \frac{N + m}{2} \right) - \left( \frac{N - m}{2} \right) \ln \left( \frac{N - m}{2} \right) - N \ln 2
\end{align*}
$$
$$
\begin{align*}
\ln p(m, N) &\approx N \ln N - \frac{N + m}{2} [\ln (N + m) - \ln 2] - \frac{N - m}{2} [\ln (N - m) - \ln 2] - N \ln 2
\end{align*}
$$

$$
\ln p(m, N) \approx N \ln N - \frac{N + m}{2} \ln (N + m) + \frac{N + m}{2} \ln 2 = - \frac{N - m}{2} \ln (N - m) + \frac{N - m}{2} \ln 2 - N \ln 2 
$$
$$\ln p(m, N) \approx N \ln N - \frac{N + m}{2} \ln (N + m) - \frac{N - m}{2} \ln (N - m) \quad + \left[ \left( \frac{N + m}{2} + \frac{N - m}{2} - N \right) \ln 2 \right]$$

$$
\large\boxed{\ln p(m, N) \approx N \ln N - \frac{N + m}{2} \ln (N + m) - \frac{N - m}{2} \ln (N - m)}
$$
**D√©veloppement limit√©** pour $m \ll N$

Lorsque $N$ est grand et $m \ll N$, nous pouvons d√©velopper les logarithmes en utilisant l'approximation de Taylor :


Voici le d√©veloppement de Taylor de $\ln(1 + x)$ au voisinage de 0 en Markdown :

Le d√©veloppement de Taylor de $\ln(1 + x)$ au voisinage de 0 est donn√© par :

$$
\ln(1 + x) = \sum_{n=1}^\infty (-1)^{n+1} \dfrac{x^n}{n} = x - \dfrac{x^2}{2} + \dfrac{x^3}{3} - \dfrac{x^4}{4} + \dfrac{x^5}{5} - \dots 
$$

 $$\ln\left(1 \pm \frac{m}{N}\right) \approx \pm \frac{m}{N} - \frac{1}{2} \left( \frac{m}{N} \right)^2$$

 $$
   \ln(N \pm m) = \ln\left(N \left(1 \pm \frac{m}{N}\right)\right) = \ln N + \ln\left(1 \pm \frac{m}{N}\right)
   $$ 
 
$$
   \ln(N \pm m) \approx \ln N + \left( \pm \frac{m}{N} - \frac{1}{2} \left( \frac{m}{N} \right)^2 \right) = \ln N \pm \frac{m}{N} - \frac{m^2}{2N^2}
   $$

**Calculons chaque terme s√©par√©ment de**

$$
\ln p(m, N) \approx N \ln N - \frac{N + m}{2} \ln (N + m) - \frac{N - m}{2} \ln (N - m)
$$

**Premier terme :**

$$
N \ln N
$$

**Deuxi√®me terme :**

$$
\begin{align*}
\frac{N + m}{2} \ln (N + m) &\approx \left( \frac{N}{2} + \frac{m}{2} \right) \left( \ln N + \frac{m}{N} - \frac{m^2}{2N^2} \right) \\
&= \frac{N}{2} \ln N + \frac{N}{2} \left( \frac{m}{N} \right) + \frac{N}{2} \left( - \frac{m^2}{2N^2} \right) \\
&\quad + \frac{m}{2} \ln N + \frac{m}{2} \left( \frac{m}{N} \right) - \frac{m}{2} \left( \frac{m^2}{2N^2} \right) \\
&= \frac{N}{2} \ln N + \frac{m}{2} + \left( - \frac{m^2}{4N} \right) + \frac{m}{2} \ln N + \frac{m^2}{2N} - \frac{m^3}{4N^2}
\end{align*}
$$

**Troisi√®me terme :**

$$
\begin{align*}
\frac{N - m}{2} \ln (N - m) &\approx \left( \frac{N}{2} - \frac{m}{2} \right) \left( \ln N - \frac{m}{N} - \frac{m^2}{2N^2} \right) \\
&= \frac{N}{2} \ln N - \frac{N}{2} \left( \frac{m}{N} \right) - \frac{N}{2} \left( \frac{m^2}{2N^2} \right) \\
&\quad - \frac{m}{2} \ln N + \frac{m}{2} \left( \frac{m}{N} \right) + \frac{m}{2} \left( \frac{m^2}{2N^2} \right) \\
&= \frac{N}{2} \ln N - \frac{m}{2} - \left( \frac{m^2}{4N} \right) - \frac{m}{2} \ln N + \frac{m^2}{2N} + \frac{m^3}{4N^2}
\end{align*}
$$

**Regroupement des termes :**

$$
\begin{align*}
\ln p(m, N) &\approx N \ln N \\
&\quad - \left[ \frac{N}{2} \ln N + \frac{m}{2} + \frac{m}{2} \ln N - \frac{m^2}{4N} + \frac{m^2}{2N} - \frac{m^3}{4N^2} \right] \\
&\quad - \left[ \frac{N}{2} \ln N - \frac{m}{2} - \frac{m}{2} \ln N - \frac{m^2}{4N} + \frac{m^2}{2N} + \frac{m^3}{4N^2} \right]
\end{align*}
$$

**Simplification des termes :**

**Les termes en $N \ln N$ :**

$$
N \ln N - \left( \frac{N}{2} \ln N + \frac{N}{2} \ln N \right) = N \ln N - N \ln N = 0
$$

**Les termes en $m$ :**

$$
- \left( \frac{m}{2} + \left( - \frac{m}{2} \right) \right) = - \left( \frac{m}{2} - \frac{m}{2} \right) = 0
$$

**Les termes en $m \ln N$ :**

$$
- \left( \frac{m}{2} \ln N + \left( - \frac{m}{2} \ln N \right) \right) = - \left( \frac{m}{2} \ln N - \frac{m}{2} \ln N \right) = 0
$$

**Les termes en $m^2$ :**

$$
- \left( + \frac{m^2}{4N} + \frac{m^2}{4N} \right) = -\frac{m^2}{2N}
$$


**Les termes en $m^3$ sont n√©gligeables pour $m \ll N$ et peuvent √™tre ignor√©s.**

**Ainsi**

$$
\ln p(m, N) \approx -\frac{m^2}{2N}
$$

**Probabilit√©**

$$
\large\boxed{p(m, N) \approx e^{- \frac{m^2}{2N}}}
$$

Ce r√©sultat montre que la probabilit√© suit une distribution gaussienne centr√©e en $m = 0$ avec une variance proportionnelle √† $N$, ce qui est conforme au th√©or√®me central limite pour une marche al√©atoire.

**Facteur de normalisation**

Pour normaliser la fonction, nous utilisons l'int√©grale gaussienne :

$$ I = \int_{-\infty}^{\infty} e^{- \alpha x^2} dx = \sqrt{\frac{\pi}{\alpha}}. $$

Dans notre cas, $\alpha = \dfrac{1}{2N}$, donc : 

$$ \int_{-\infty}^{\infty} e^{- \frac{m^2}{N}} dm = \sqrt{2\pi N}.$$ 

Le facteur de normalisation est donc $\dfrac{1}{\sqrt{\pi N}}$. Ainsi, la densit√© de probabilit√© normalis√©e est : 

$$ P(m) = \frac{1}{\sqrt{2\pi N}} e^{- \frac{m^2}{2N}}. $$

La probabilit√© de trouver l'ivrogne en position $m$ apr√®s $N$ pas est donn√©e par :

$$
\large\boxed{P(m) = \frac{1}{\sqrt{2\pi N}} \exp \left( - \dfrac{m^2}{2N} \right)}
$$

> [!NOTE] Int√©r√™t de l'approximation de Stirling ici
> L'utilisation de l'approximation de Stirling est particuli√®rement utile lorsque le nombre de pas $N$ est grand. Elle permet de simplifier les calculs en rempla√ßant les factorielles par des expressions plus faciles √† manipuler. 
> 
> Dans le cas de l'ivrogne :
> - **Simplicit√© de calcul** : Elle √©vite le calcul direct de factorielles de grands nombres, qui peut √™tre complexe et impraticable.
> - **Approche asymptotique** : Elle fournit une approximation valable pour $N \gg 1$, ce qui est souvent le cas dans les probl√®mes physiques et statistiques.
> - **Lien avec la loi normale** : Elle permet de montrer que la distribution binomiale tend vers une loi normale lorsque $N$ est grand, ce qui est une manifestation du th√©or√®me central limite.

## Code

### Version vectoris√©e 
```python
# Importation des biblioth√®ques n√©cessaires  
import numpy as np  
import matplotlib  
import matplotlib.pyplot as plt  
  
# Configuration des param√®tres de Matplotlib pour les graphiques  
matplotlib.rcParams['figure.dpi'] = 150  # R√©solution des images  
  
# Constantes  
NBR_IVROGNES = 2000  
liste_NBR_PAS = (  
        list(range(10, 110, 20)) +  
        list(range(200, 1100, 200)) +  
        list(range(2000, 11000, 2000)) +  
        list(range(20000, 110000, 20000)) +  
        list(range(200000, 1000000, 200000))  
)  
distances_quadratiques_moyennes = []  # Liste pour stocker les distances quadratiques moyennes  
distances_theoriques = []  # Liste pour stocker les distances th√©oriques  
  
# Simulation pour chaque nombre de pas  
for NBR_PAS in liste_NBR_PAS:  
    # G√©n√©ration de tous les pas al√©atoires en une seule fois  
    pas = np.random.choice([-1, 1], size=(NBR_IVROGNES, NBR_PAS))  
    # Calcul des positions finales en sommant les pas  
    positions_finales = pas.sum(axis=1)  
    # Calcul de la distance quadratique moyenne pour ce nombre de pas  
    distances_quadratiques = positions_finales ** 2  
    distance_quadratique_moyenne = distances_quadratiques.mean()  
    distances_quadratiques_moyennes.append(distance_quadratique_moyenne)  
    # Calcul de la distance th√©orique  
    distance_theorique = NBR_PAS  # Pour une marche al√©atoire simple en 1D  
    distances_theoriques.append(distance_theorique)  
  
# Conversion en tableaux numpy pour faciliter le trac√©  
liste_NBR_PAS_np = np.array(liste_NBR_PAS)  
distances_quadratiques_moyennes_np = np.array(distances_quadratiques_moyennes)  
distances_theoriques_np = np.array(distances_theoriques)  
  
# Cr√©ation du graphique  
plt.figure(figsize=(8, 5))  
plt.plot(liste_NBR_PAS_np, distances_theoriques_np, '--', label='Th√©orie')  
plt.plot(liste_NBR_PAS_np, distances_quadratiques_moyennes_np, 'o', label='Simulation', markeredgewidth=2, markersize=2)  
plt.xscale('log')  
plt.yscale('log')  
plt.xlabel('Nombre de pas (√©chelle logarithmique)')  
plt.ylabel('Distance quadratique moyenne $\\langle x^2 \\rangle$')  
plt.title('$\\langle x^2 \\rangle$ = f(nombre de pas)    (Vectoris√©)')  
plt.legend()  
plt.grid(True, which="both", ls="--")  
plt.figtext(0.70, 0.015, 'www.sciences-physiques.net', fontsize=6, color='black', alpha=0.9, fontweight='normal')  
plt.show()
```
```{image} ../_static/_medias/physic/thermo/brown/Vectorize.png
:align: center
:class: vspace
```


### Version utilisant pytorch et CUDA (de NVidia)
```python
# Importation des biblioth√®ques n√©cessaires  
import torch  
import matplotlib  
import matplotlib.pyplot as plt  
  
# Configuration des param√®tres de Matplotlib pour les graphiques  
matplotlib.rcParams['figure.dpi'] = 150  # R√©solution des images  
  
# D√©tection du dispositif (CPU ou GPU)  
dispositif = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  
print(f"Utilisation du dispositif : {dispositif}")  
  
# Constantes  
NBR_IVROGNES = 2000  
liste_NBR_PAS = (  
        list(range(10, 110, 20)) +  
        list(range(200, 1100, 200)) +  
        list(range(2000, 11000, 2000)) +  
        list(range(20000, 110000, 20000)) +  
        list(range(200000, 1000000, 200000))  
)  
distances_quadratiques_moyennes = []  # Liste pour stocker les distances quadratiques moyennes  
distances_theoriques = []  # Liste pour stocker les distances th√©oriques  
  
# Simulation pour chaque nombre de pas  
for NBR_PAS in liste_NBR_PAS:  
    # G√©n√©ration de tous les pas al√©atoires en une seule fois sur le dispositif choisi  
    pas = torch.randint(0, 2, (NBR_IVROGNES, NBR_PAS), device=dispositif, dtype=torch.int8) * 2 - 1  
    # Calcul des positions finales en sommant les pas  
    positions_finales = pas.sum(dim=1)  
    # Calcul de la distance quadratique moyenne pour ce nombre de pas  
    distances_quadratiques = positions_finales.float() ** 2  
    distance_quadratique_moyenne = distances_quadratiques.mean().item()  
    distances_quadratiques_moyennes.append(distance_quadratique_moyenne)  
    # Calcul de la distance th√©orique  
    distance_theorique = NBR_PAS  # Pour une marche al√©atoire simple en 1D  
    distances_theoriques.append(distance_theorique)  
  
# Conversion en tensors pour faciliter le trac√©  
liste_NBR_PAS_tensor = torch.tensor(liste_NBR_PAS)  
distances_quadratiques_moyennes_tensor = torch.tensor(distances_quadratiques_moyennes)  
distances_theoriques_tensor = torch.tensor(distances_theoriques)  
  
# Cr√©ation du graphique  
plt.figure(figsize=(8, 5))  
plt.plot(liste_NBR_PAS_tensor.numpy(), distances_theoriques_tensor.numpy(), '--', label='Th√©orie')  
plt.plot(liste_NBR_PAS_tensor.numpy(), distances_quadratiques_moyennes_tensor.numpy(), 'o', label='Simulation',  
         markeredgewidth=2, markersize=2)  
plt.xscale('log')  
plt.yscale('log')  
plt.xlabel('Nombre de pas (√©chelle logarithmique)')  
plt.ylabel('Distance quadratique moyenne $\\langle x^2 \\rangle$')  
plt.title('$\\langle x^2 \\rangle$ = f(nombre de pas)    (PyTorch)')  
plt.legend()  
plt.grid(True, which="both", ls="--")  
plt.figtext(0.70, 0.015, 'www.sciences-physiques.net', fontsize=6, color='black', alpha=0.9, fontweight='normal')  
plt.show()
```

```{image} ../_static/_medias/physic/thermo/brown/CUDA.png
:align: center
:class: vspace
```

# Sources et autres liens
[^1]: [Biographie de Robert Brown](https://fr.wikipedia.org/wiki/Robert_Brown_(botaniste))
[^2]: [Biographie de Jean Perrin](https://fr.wikipedia.org/wiki/Jean_Perrin)
[^3]: Vid√©o de [Science-questions](https://fr.science-questions.org/questions_de_science/166/Qu_est-ce_que_le_mouvement_brownien/)
